{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CQKP Example",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Load Pretrained CQKP\n",
        "(you'll have to sign into wandb)"
      ],
      "metadata": {
        "id": "zRhLZ7NPmB47"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9QJEYvOXjp9D"
      },
      "outputs": [],
      "source": [
        "!pip install transformers wandb\n",
        "from google.colab import output\n",
        "output.clear()\n",
        "import wandb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from transformers import DistilBertModel, DistilBertConfig, DistilBertTokenizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextEncoder(nn.Module):\n",
        "    def __init__(self, model_name=\"distilbert-base-uncased\", pretrained=True, trainable=False):\n",
        "        super().__init__()\n",
        "        if pretrained:\n",
        "            self.model = DistilBertModel.from_pretrained(model_name)\n",
        "        else:\n",
        "            self.model = DistilBertModel(config=DistilBertConfig())\n",
        "        for p in self.model.parameters():\n",
        "            p.requires_grad = trainable\n",
        "        self.target_token_idx = 0\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        last_hidden_state = output.last_hidden_state\n",
        "        return last_hidden_state[:, self.target_token_idx, :]\n",
        "class ProjectionHead(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_dim,\n",
        "        projection_dim=1024,\n",
        "        dropout=0.1\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.projection = nn.Linear(embedding_dim, projection_dim)\n",
        "        self.gelu = nn.GELU()\n",
        "        self.fc = nn.Linear(projection_dim, projection_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm = nn.LayerNorm(projection_dim)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        projected = self.projection(x)\n",
        "        x = self.gelu(projected)\n",
        "        x = self.fc(x)\n",
        "        x = self.dropout(x)\n",
        "        x = x + projected\n",
        "        x = self.layer_norm(x)\n",
        "        return x\n",
        "\n",
        "class CKQP_Model(nn.Module):\n",
        "    def __init__(\n",
        "        self,   \n",
        "        temperature=1.,\n",
        "        image_embedding=768,\n",
        "        text_embedding=768,\n",
        "        max_length=256\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.text_encoder = TextEncoder()\n",
        "        self.question_encoder = TextEncoder()\n",
        "\n",
        "        self.question_projection = ProjectionHead(embedding_dim=text_embedding)\n",
        "        self.text_projection = ProjectionHead(embedding_dim=text_embedding)\n",
        "        self.temperature = temperature\n",
        "        self.tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "        self.max_length = max_length\n",
        "    def tokenize(self, texts):\n",
        "        return self.tokenizer(\n",
        "            list([str(text) for text in texts]), padding=True, truncation=True, max_length=self.max_length\n",
        "        )\n",
        "    def forward(self, text_features, question_features, mask1, mask2):\n",
        "        # mask= torch.ones(16, 1, 1, 20).to(device)\n",
        "        text_features = self.text_encoder(text_features,mask1)\n",
        "        question_features = self.question_encoder(question_features,mask2)\n",
        "        question_embeddings = self.question_projection(question_features)\n",
        "        text_embeddings = self.text_projection(text_features)\n",
        "\n",
        "        logits = (text_embeddings @ question_embeddings.T) / self.temperature\n",
        "        questions_similarity = question_features @ question_features.T\n",
        "        texts_similarity = text_embeddings @ text_embeddings.T\n",
        "        targets = F.softmax(\n",
        "            (questions_similarity + texts_similarity) / 2 * self.temperature, dim=-1\n",
        "        )\n",
        "        texts_loss = cross_entropy(logits, targets, reduction='none')\n",
        "        questions_loss = cross_entropy(logits.T, targets.T, reduction='none')\n",
        "        loss =  (questions_loss + texts_loss) / 2.0 # shape: (batch_size)\n",
        "        return loss.mean()\n",
        "    def score(self,questions,answers):\n",
        "        text_features = self.text_encoder(torch.tensor(answers['input_ids'], device=device),torch.tensor(answers['attention_mask'],device=device))\n",
        "        question_features = self.question_encoder(torch.tensor(questions['input_ids'],device=device),torch.tensor(questions['attention_mask'],device=device))\n",
        "        question_embeddings = self.question_projection(question_features)\n",
        "        text_embeddings = self.text_projection(text_features)\n",
        "        return question_embeddings, text_embeddings\n",
        "    def best_answer(self, question, answers):\n",
        "        q_tok = self.tokenize([question])\n",
        "        a_tok = self.tokenize(answers)\n",
        "        scores = self.score(q_tok,a_tok)\n",
        "        scores = [torch.nn.functional.cosine_similarity(scores[0], scores[1][i]).item() for i in range(len(scores[1]))]\n",
        "        ind = scores.index(max(scores))\n",
        "        return (answers[ind], ind, max(scores))\n",
        "    def best_question(self, questions, answer):\n",
        "        q_tok = self.tokenize(questions)\n",
        "        a_tok = self.tokenize([answer])\n",
        "        scores = self.score(q_tok,a_tok)\n",
        "        scores = [torch.nn.functional.cosine_similarity(scores[0][i], scores[1]).item() for i in range(len(scores[0]))]\n",
        "        ind = scores.index(max(scores))\n",
        "        return (questions[ind], ind, max(scores))\n",
        "def cross_entropy(preds, targets, reduction='none'):\n",
        "    log_softmax = nn.LogSoftmax(dim=-1)\n",
        "    loss = (-targets * log_softmax(preds)).sum(1)\n",
        "    if reduction == \"none\":\n",
        "        return loss\n",
        "    elif reduction == \"mean\":\n",
        "        return loss.mean()"
      ],
      "metadata": {
        "id": "5N0tcKovlPQW"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.restore('SQuAD_CQKP.pt', run_path=\"boopysaur/CQKP/1nfqx9u0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "nghuQHkHkGIb",
        "outputId": "448af100-56d1-4fc0-dbc6-f8749f047f5a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_io.TextIOWrapper name='/content/SQuAD_CQKP.pt' mode='r' encoding='UTF-8'>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cqkp(path=\"SQuAD_CQKP.pt\",device):\n",
        "    model = CKQP_Model().to(device)\n",
        "    model.load_state_dict(torch.load(path),map_location=device)\n",
        "    return model.eval()"
      ],
      "metadata": {
        "id": "7NgOIkHalSj-"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cqkp = load_cqkp()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WEDuXlUmIWv",
        "outputId": "f5a8a54f-9ed7-46fc-b5de-18727d2b840b"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Examples\n"
      ],
      "metadata": {
        "id": "_8Fze17wmFLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Success \n",
        "# (both answers purposefully use the word bird to prove it isn't just comparing similar tokens)\n",
        "articles = [\n",
        "    \"Birds can eat all nuts other than the usual peanuts\",\n",
        "    \"Birds are a group of warm-blooded vertebrates constituting the class Aves\",\n",
        "]\n",
        "cqkp.best_answer(\"what is a bird?\", articles)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8kRPB81atpVI",
        "outputId": "a67895f7-1afb-4379-a292-6baf39b764b9"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Birds are a group of warm-blooded vertebrates constituting the class Aves'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    \"what is a bird?\",\n",
        "    \"what nuts can birds eat?\"\n",
        "]\n",
        "answer = \"Birds can eat all nuts other than the usual peanuts\"\n",
        "cqkp.best_question(questions,answer)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "skf9rIfNv-BA",
        "outputId": "c55c1220-884b-431e-f5a8-add5009f1433"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'what nuts can birds eat?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Failure\n",
        "articles = [\n",
        "    \"The square root of 9 is 3\",\n",
        "    \"The square root of 16 is 4\"\n",
        "]\n",
        "cqkp.best_answer(\"whats the square root of nine?\", articles)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SbNTsEvUvCnX",
        "outputId": "f4a59b59-3125-40cd-9f42-f3a05c06920c"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The square root of 16 is 4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    }
  ]
}